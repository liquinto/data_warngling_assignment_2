{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96765a09-de2c-47d4-9a68-9ea4b2a0b6f4",
   "metadata": {},
   "source": [
    "# INFOMDWR – Assignment 2: Data Integration & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce808c57-f79c-4f3b-ac74-d10da39d4e8f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this assignment, you will work on different tasks that are related to data preparation including data profiling, finding records that refer to same entity, and computing the correlation between different attributes. The datasets that you need to work on are available online (links are provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6092e9-4843-4b76-95f0-e7f73e2710e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "from typing import Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from py_stringmatching import similarity_measure as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a2a98575-577b-4329-965e-5e4b78216bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collision_index</th>\n",
       "      <th>collision_year</th>\n",
       "      <th>collision_ref_no</th>\n",
       "      <th>location_easting_osgr</th>\n",
       "      <th>location_northing_osgr</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>police_force</th>\n",
       "      <th>collision_severity</th>\n",
       "      <th>number_of_vehicles</th>\n",
       "      <th>...</th>\n",
       "      <th>carriageway_hazards_historic</th>\n",
       "      <th>carriageway_hazards</th>\n",
       "      <th>urban_or_rural_area</th>\n",
       "      <th>did_police_officer_attend_scene_of_accident</th>\n",
       "      <th>trunk_road_flag</th>\n",
       "      <th>lsoa_of_accident_location</th>\n",
       "      <th>enhanced_severity_collision</th>\n",
       "      <th>collision_injury_based</th>\n",
       "      <th>collision_adjusted_severity_serious</th>\n",
       "      <th>collision_adjusted_severity_slight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202417H103224</td>\n",
       "      <td>2024</td>\n",
       "      <td>17H103224</td>\n",
       "      <td>448894</td>\n",
       "      <td>532505</td>\n",
       "      <td>-1.24312</td>\n",
       "      <td>54.68523</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>E01011983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202417M217924</td>\n",
       "      <td>2024</td>\n",
       "      <td>17M217924</td>\n",
       "      <td>452135</td>\n",
       "      <td>519436</td>\n",
       "      <td>-1.19517</td>\n",
       "      <td>54.56747</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>E01012061</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202417S204524</td>\n",
       "      <td>2024</td>\n",
       "      <td>17S204524</td>\n",
       "      <td>445427</td>\n",
       "      <td>522924</td>\n",
       "      <td>-1.29837</td>\n",
       "      <td>54.59946</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>E01012280</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111621</td>\n",
       "      <td>0.888379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024481510889</td>\n",
       "      <td>2024</td>\n",
       "      <td>481510889</td>\n",
       "      <td>533587</td>\n",
       "      <td>181174</td>\n",
       "      <td>-0.07626</td>\n",
       "      <td>51.51371</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>E01000005</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024481563500</td>\n",
       "      <td>2024</td>\n",
       "      <td>481563500</td>\n",
       "      <td>532676</td>\n",
       "      <td>180902</td>\n",
       "      <td>-0.08948</td>\n",
       "      <td>51.51148</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>E01032739</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100922</th>\n",
       "      <td>2024991432330</td>\n",
       "      <td>2024</td>\n",
       "      <td>991432330</td>\n",
       "      <td>255558</td>\n",
       "      <td>666585</td>\n",
       "      <td>-4.31001</td>\n",
       "      <td>55.87072</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100923</th>\n",
       "      <td>2024991466055</td>\n",
       "      <td>2024</td>\n",
       "      <td>991466055</td>\n",
       "      <td>258265</td>\n",
       "      <td>666632</td>\n",
       "      <td>-4.26681</td>\n",
       "      <td>55.87194</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100924</th>\n",
       "      <td>2024991485880</td>\n",
       "      <td>2024</td>\n",
       "      <td>991485880</td>\n",
       "      <td>264189</td>\n",
       "      <td>664898</td>\n",
       "      <td>-4.17134</td>\n",
       "      <td>55.85808</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100925</th>\n",
       "      <td>2024991436758</td>\n",
       "      <td>2024</td>\n",
       "      <td>991436758</td>\n",
       "      <td>291004</td>\n",
       "      <td>658589</td>\n",
       "      <td>-3.74065</td>\n",
       "      <td>55.80823</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100926</th>\n",
       "      <td>2024991510586</td>\n",
       "      <td>2024</td>\n",
       "      <td>991510586</td>\n",
       "      <td>276234</td>\n",
       "      <td>660212</td>\n",
       "      <td>-3.97690</td>\n",
       "      <td>55.81925</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100927 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       collision_index  collision_year collision_ref_no  \\\n",
       "0        202417H103224            2024        17H103224   \n",
       "1        202417M217924            2024        17M217924   \n",
       "2        202417S204524            2024        17S204524   \n",
       "3        2024481510889            2024        481510889   \n",
       "4        2024481563500            2024        481563500   \n",
       "...                ...             ...              ...   \n",
       "100922   2024991432330            2024        991432330   \n",
       "100923   2024991466055            2024        991466055   \n",
       "100924   2024991485880            2024        991485880   \n",
       "100925   2024991436758            2024        991436758   \n",
       "100926   2024991510586            2024        991510586   \n",
       "\n",
       "        location_easting_osgr  location_northing_osgr  longitude  latitude  \\\n",
       "0                      448894                  532505   -1.24312  54.68523   \n",
       "1                      452135                  519436   -1.19517  54.56747   \n",
       "2                      445427                  522924   -1.29837  54.59946   \n",
       "3                      533587                  181174   -0.07626  51.51371   \n",
       "4                      532676                  180902   -0.08948  51.51148   \n",
       "...                       ...                     ...        ...       ...   \n",
       "100922                 255558                  666585   -4.31001  55.87072   \n",
       "100923                 258265                  666632   -4.26681  55.87194   \n",
       "100924                 264189                  664898   -4.17134  55.85808   \n",
       "100925                 291004                  658589   -3.74065  55.80823   \n",
       "100926                 276234                  660212   -3.97690  55.81925   \n",
       "\n",
       "        police_force  collision_severity  number_of_vehicles  ...  \\\n",
       "0                 17                   3                   2  ...   \n",
       "1                 17                   2                   2  ...   \n",
       "2                 17                   3                   2  ...   \n",
       "3                 48                   2                   1  ...   \n",
       "4                 48                   2                   1  ...   \n",
       "...              ...                 ...                 ...  ...   \n",
       "100922            99                   2                   1  ...   \n",
       "100923            99                   3                   1  ...   \n",
       "100924            99                   2                   2  ...   \n",
       "100925            99                   3                   2  ...   \n",
       "100926            99                   2                   1  ...   \n",
       "\n",
       "        carriageway_hazards_historic carriageway_hazards  urban_or_rural_area  \\\n",
       "0                                 -1                   0                    1   \n",
       "1                                 -1                   0                    1   \n",
       "2                                  0                   0                    2   \n",
       "3                                 -1                   0                    1   \n",
       "4                                 -1                   0                    1   \n",
       "...                              ...                 ...                  ...   \n",
       "100922                            -1                   0                    1   \n",
       "100923                            -1                   0                    1   \n",
       "100924                            -1                   0                    1   \n",
       "100925                            -1                   0                    2   \n",
       "100926                            -1                   0                    1   \n",
       "\n",
       "       did_police_officer_attend_scene_of_accident  trunk_road_flag  \\\n",
       "0                                                2                2   \n",
       "1                                                3                2   \n",
       "2                                                1                2   \n",
       "3                                                1                2   \n",
       "4                                                1                2   \n",
       "...                                            ...              ...   \n",
       "100922                                           1               -1   \n",
       "100923                                           1               -1   \n",
       "100924                                           1               -1   \n",
       "100925                                           1               -1   \n",
       "100926                                           1               -1   \n",
       "\n",
       "       lsoa_of_accident_location enhanced_severity_collision  \\\n",
       "0                      E01011983                           3   \n",
       "1                      E01012061                           7   \n",
       "2                      E01012280                          -1   \n",
       "3                      E01000005                           7   \n",
       "4                      E01032739                           5   \n",
       "...                          ...                         ...   \n",
       "100922                        -1                           6   \n",
       "100923                        -1                           3   \n",
       "100924                        -1                           7   \n",
       "100925                        -1                           3   \n",
       "100926                        -1                           5   \n",
       "\n",
       "       collision_injury_based  collision_adjusted_severity_serious  \\\n",
       "0                           1                             0.000000   \n",
       "1                           1                             1.000000   \n",
       "2                           0                             0.111621   \n",
       "3                           1                             1.000000   \n",
       "4                           1                             1.000000   \n",
       "...                       ...                                  ...   \n",
       "100922                      1                             1.000000   \n",
       "100923                      1                             0.000000   \n",
       "100924                      1                             1.000000   \n",
       "100925                      1                             0.000000   \n",
       "100926                      1                             1.000000   \n",
       "\n",
       "        collision_adjusted_severity_slight  \n",
       "0                                 1.000000  \n",
       "1                                 0.000000  \n",
       "2                                 0.888379  \n",
       "3                                 0.000000  \n",
       "4                                 0.000000  \n",
       "...                                    ...  \n",
       "100922                            0.000000  \n",
       "100923                            1.000000  \n",
       "100924                            0.000000  \n",
       "100925                            1.000000  \n",
       "100926                            0.000000  \n",
       "\n",
       "[100927 rows x 44 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the csv into a dataframe and print a part of the dataframe\n",
    "\n",
    "df = pd.read_csv(\"dft-road-casualty-statistics-collision-2024.csv\", low_memory = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed268c-64bc-40ef-9635-2943d5093ce0",
   "metadata": {},
   "source": [
    "## Task 1: Profiling relational data\n",
    "\n",
    "For this task, download and read the paper about profiling relational data, select a set of summary statistics about the data (minimum of 10 different values) and write Python code to compute these quantities for a dataset of your choice. Preferably, you can use one of the csv files from the road safety dataset. Explain the importance of each summary statistic that you selected in understanding the characteristics of the dataset.\n",
    "\n",
    "*Note: Computing the same statistical quantity on multiple columns of the dataset will be counted only once.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ee272e1f-1357-4e92-bb6e-5733744fcbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to hold the summary statistics\n",
    "\n",
    "summary_statistics: dict[str, Any] = {\n",
    "    \"mean\": None,\n",
    "    \"median\": None,\n",
    "    \"mode\": None,\n",
    "    \"minimum\": None,\n",
    "    \"maximum\": None,\n",
    "    \"range\": None,\n",
    "    \"variance\": None,\n",
    "    \"standard_deviation\": None,\n",
    "    \"records\": None,\n",
    "    \"number_of_missing_records\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ed94994-70cd-4538-aac1-6dac87a690a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': np.float64(35.87966550080751),\n",
       " 'median': np.float64(30.0),\n",
       " 'mode': 0    30\n",
       " Name: speed_limit, dtype: int64,\n",
       " 'minimum': np.int64(-1),\n",
       " 'maximum': np.int64(70),\n",
       " 'range': np.int64(71),\n",
       " 'variance': np.float64(211.30421831349014),\n",
       " 'standard_deviation': np.float64(14.536306900774012),\n",
       " 'records': 100927,\n",
       " 'number_of_missing_records': np.int64(3)}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the dictionary for summary statistics\n",
    "\n",
    "summary_statistics[\"mean\"] = df[\"speed_limit\"].mean()                                           # Mean of the speed limit\n",
    "summary_statistics[\"median\"] = df[\"speed_limit\"].median()                                       # Median of the speed limit \n",
    "summary_statistics[\"mode\"] = df[\"speed_limit\"].mode()                                           # Mode of the speed limit\n",
    "summary_statistics[\"minimum\"] = df[\"speed_limit\"].min()                                         # Min of the speed limit\n",
    "summary_statistics[\"maximum\"] = df[\"speed_limit\"].max()                                         # Max of the speed limit\n",
    "summary_statistics[\"range\"] = abs(df[\"speed_limit\"].max()) + abs(df[\"speed_limit\"].min())       # Range of the speed limit, thus abs(max)+ and(min))\n",
    "summary_statistics[\"variance\"] = df[\"speed_limit\"].var()                                        # Variance of the speed limit\n",
    "summary_statistics[\"standard_deviation\"] = df[\"speed_limit\"].std()                              # Standard deviation of the speed limit\n",
    "summary_statistics[\"records\"] = len(df[\"speed_limit\"])                                          # Number of rows in the dataframe\n",
    "summary_statistics[\"number_of_missing_records\"] = df.isnull().sum().sum()                       # Number of missing values in the entire dataframe\n",
    "\n",
    "summary_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9147cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b98bbe-e4db-410e-ada7-ce9bfbc2a5c4",
   "metadata": {},
   "source": [
    "## Task 2: Entity resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd598718-2a4c-4cd5-9cf1-291d8ded1bfb",
   "metadata": {},
   "source": [
    "### Part 1:\n",
    "\n",
    "Write a Python code to compare every single record in the dataset (ACM.csv) with all the records in (DBLP2.csv) and find the similar records (records that represent the same publication). To compare two records, follow the steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ad8a3386-2363-4be4-a598-bd1d8808210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "\n",
    "df_acm = pd.read_csv(\"ACM.csv\")\n",
    "df_dblp2 = pd.read_csv(\"DBLP2.csv\", encoding=\"latin1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8d176b90-d11b-40a4-ba35-15c9a6fb5159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304586</td>\n",
       "      <td>The WASA2 object-oriented workflow management ...</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304587</td>\n",
       "      <td>A user-centered interface for querying distrib...</td>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304589</td>\n",
       "      <td>World Wide Database-integrating the Web, CORBA...</td>\n",
       "      <td>Athman Bouguettaya, Boualem Benatallah, Lily H...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304590</td>\n",
       "      <td>XML-based information mediation with MIX</td>\n",
       "      <td>Chaitan Baru, Amarnath Gupta, Bertram Lud&amp;#228...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304582</td>\n",
       "      <td>The CCUBE constraint object-oriented database ...</td>\n",
       "      <td>Alexander Brodsky, Victor E. Segal, Jia Chen, ...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>672977</td>\n",
       "      <td>Dual-Buffering Strategies in Object Bases</td>\n",
       "      <td>Alfons Kemper, Donald Kossmann</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>950482</td>\n",
       "      <td>Guest editorial</td>\n",
       "      <td>Philip A. Bernstein, Yannis Ioannidis, Raghu R...</td>\n",
       "      <td>The VLDB Journal &amp;mdash; The International Jou...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>672980</td>\n",
       "      <td>GraphDB: Modeling and Querying Graphs in Datab...</td>\n",
       "      <td>Ralf Hartmut G&amp;#252;ting</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>945741</td>\n",
       "      <td>Review of The data warehouse toolkit: the comp...</td>\n",
       "      <td>Alexander A. Anisimov</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>672979</td>\n",
       "      <td>Bulk Loading into an OODB: A Performance Study</td>\n",
       "      <td>Janet L. Wiener, Jeffrey F. Naughton</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2294 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0     304586  The WASA2 object-oriented workflow management ...   \n",
       "1     304587  A user-centered interface for querying distrib...   \n",
       "2     304589  World Wide Database-integrating the Web, CORBA...   \n",
       "3     304590           XML-based information mediation with MIX   \n",
       "4     304582  The CCUBE constraint object-oriented database ...   \n",
       "...      ...                                                ...   \n",
       "2289  672977          Dual-Buffering Strategies in Object Bases   \n",
       "2290  950482                                    Guest editorial   \n",
       "2291  672980  GraphDB: Modeling and Querying Graphs in Datab...   \n",
       "2292  945741  Review of The data warehouse toolkit: the comp...   \n",
       "2293  672979     Bulk Loading into an OODB: A Performance Study   \n",
       "\n",
       "                                                authors  \\\n",
       "0                       Gottfried Vossen, Mathias Weske   \n",
       "1                     Isabel F. Cruz, Kimberly M. James   \n",
       "2     Athman Bouguettaya, Boualem Benatallah, Lily H...   \n",
       "3     Chaitan Baru, Amarnath Gupta, Bertram Lud&#228...   \n",
       "4     Alexander Brodsky, Victor E. Segal, Jia Chen, ...   \n",
       "...                                                 ...   \n",
       "2289                     Alfons Kemper, Donald Kossmann   \n",
       "2290  Philip A. Bernstein, Yannis Ioannidis, Raghu R...   \n",
       "2291                           Ralf Hartmut G&#252;ting   \n",
       "2292                              Alexander A. Anisimov   \n",
       "2293               Janet L. Wiener, Jeffrey F. Naughton   \n",
       "\n",
       "                                                  venue  year  \n",
       "0        International Conference on Management of Data  1999  \n",
       "1        International Conference on Management of Data  1999  \n",
       "2        International Conference on Management of Data  1999  \n",
       "3        International Conference on Management of Data  1999  \n",
       "4        International Conference on Management of Data  1999  \n",
       "...                                                 ...   ...  \n",
       "2289                              Very Large Data Bases  1994  \n",
       "2290  The VLDB Journal &mdash; The International Jou...  2003  \n",
       "2291                              Very Large Data Bases  1994  \n",
       "2292                                 ACM SIGMOD Record   2003  \n",
       "2293                              Very Large Data Bases  1994  \n",
       "\n",
       "[2294 rows x 5 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataframe of ACM\n",
    "\n",
    "df_acm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d7d7edf1-6712-417f-b524-8a2134c2eb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models f...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/vldb/PoosalaI96</td>\n",
       "      <td>Estimation of Query-Result Distribution and it...</td>\n",
       "      <td>Viswanath Poosala, Yannis E. Ioannidis</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conf/vldb/PalpanasSCP02</td>\n",
       "      <td>Incremental Maintenance for Non-Distributive A...</td>\n",
       "      <td>Themistoklis Palpanas, Richard Sidle, Hamid Pi...</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conf/vldb/GardarinGT96</td>\n",
       "      <td>Cost-based Selection of Path Expression Proces...</td>\n",
       "      <td>Zhao-Hui Tang, Georges Gardarin, Jean-Robert G...</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conf/vldb/HoelS95</td>\n",
       "      <td>Benchmarking Spatial Join Operations with Spat...</td>\n",
       "      <td>Erik G. Hoel, Hanan Samet</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>journals/tods/KarpSP03</td>\n",
       "      <td>A simple algorithm for finding frequent elemen...</td>\n",
       "      <td>Scott Shenker, Christos H. Papadimitriou, Rich...</td>\n",
       "      <td>ACM Trans. Database Syst.</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>conf/vldb/LimWV03</td>\n",
       "      <td>SASH: A Self-Adaptive Histogram Set for Dynami...</td>\n",
       "      <td>Lipyeow Lim, Min Wang, Jeffrey Scott Vitter</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>journals/tods/ChakrabartiKMP02</td>\n",
       "      <td>Locally adaptive dimensionality reduction for ...</td>\n",
       "      <td>Kaushik Chakrabarti, Eamonn J. Keogh, Michael ...</td>\n",
       "      <td>ACM Trans. Database Syst.</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>journals/sigmod/Snodgrass01</td>\n",
       "      <td>Chair's Message</td>\n",
       "      <td>Richard T. Snodgrass</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>conf/vldb/LiM01</td>\n",
       "      <td>Indexing and Querying XML Data for Regular Pat...</td>\n",
       "      <td>Bongki Moon, Quanzhong Li</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2616 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0           journals/sigmod/Mackay99   \n",
       "1               conf/vldb/PoosalaI96   \n",
       "2            conf/vldb/PalpanasSCP02   \n",
       "3             conf/vldb/GardarinGT96   \n",
       "4                  conf/vldb/HoelS95   \n",
       "...                              ...   \n",
       "2611          journals/tods/KarpSP03   \n",
       "2612               conf/vldb/LimWV03   \n",
       "2613  journals/tods/ChakrabartiKMP02   \n",
       "2614     journals/sigmod/Snodgrass01   \n",
       "2615                 conf/vldb/LiM01   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Semantic Integration of Environmental Models f...   \n",
       "1     Estimation of Query-Result Distribution and it...   \n",
       "2     Incremental Maintenance for Non-Distributive A...   \n",
       "3     Cost-based Selection of Path Expression Proces...   \n",
       "4     Benchmarking Spatial Join Operations with Spat...   \n",
       "...                                                 ...   \n",
       "2611  A simple algorithm for finding frequent elemen...   \n",
       "2612  SASH: A Self-Adaptive Histogram Set for Dynami...   \n",
       "2613  Locally adaptive dimensionality reduction for ...   \n",
       "2614                                    Chair's Message   \n",
       "2615  Indexing and Querying XML Data for Regular Pat...   \n",
       "\n",
       "                                                authors  \\\n",
       "0                                       D. Scott Mackay   \n",
       "1                Viswanath Poosala, Yannis E. Ioannidis   \n",
       "2     Themistoklis Palpanas, Richard Sidle, Hamid Pi...   \n",
       "3     Zhao-Hui Tang, Georges Gardarin, Jean-Robert G...   \n",
       "4                             Erik G. Hoel, Hanan Samet   \n",
       "...                                                 ...   \n",
       "2611  Scott Shenker, Christos H. Papadimitriou, Rich...   \n",
       "2612        Lipyeow Lim, Min Wang, Jeffrey Scott Vitter   \n",
       "2613  Kaushik Chakrabarti, Eamonn J. Keogh, Michael ...   \n",
       "2614                               Richard T. Snodgrass   \n",
       "2615                          Bongki Moon, Quanzhong Li   \n",
       "\n",
       "                          venue  year  \n",
       "0                 SIGMOD Record  1999  \n",
       "1                          VLDB  1996  \n",
       "2                          VLDB  2002  \n",
       "3                          VLDB  1996  \n",
       "4                          VLDB  1995  \n",
       "...                         ...   ...  \n",
       "2611  ACM Trans. Database Syst.  2003  \n",
       "2612                       VLDB  2003  \n",
       "2613  ACM Trans. Database Syst.  2002  \n",
       "2614              SIGMOD Record  2001  \n",
       "2615                       VLDB  2001  \n",
       "\n",
       "[2616 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataframe of dblp2\n",
    "\n",
    "df_dblp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31341a-5a97-468e-a3e6-9fdadaaa56c5",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "### A. \n",
    "\n",
    "Ignore the pub_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "65d281a4-2cce-4967-97e2-5b4c3fca9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acm.drop(\"id\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "96d3ff88-4d31-433a-80e0-29c88a5be158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dblp2.drop(\"id\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c0854-19a6-4467-a694-da679894ab20",
   "metadata": {},
   "source": [
    "### B. \n",
    "\n",
    "Change all alphabetical characters into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5e5a4c03-6e1d-4c56-b5bd-d9961bc54c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_acm.columns:\n",
    "    df_acm[col] = df_acm[col].astype(str).str.lower()\n",
    "for col in df_dblp2.columns:\n",
    "    df_dblp2[col] = df_dblp2[col].astype(str).str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9478fd61-8679-43e0-aa9d-d99b04982f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the wasa2 object-oriented workflow management ...</td>\n",
       "      <td>gottfried vossen, mathias weske</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a user-centered interface for querying distrib...</td>\n",
       "      <td>isabel f. cruz, kimberly m. james</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world wide database-integrating the web, corba...</td>\n",
       "      <td>athman bouguettaya, boualem benatallah, lily h...</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xml-based information mediation with mix</td>\n",
       "      <td>chaitan baru, amarnath gupta, bertram lud&amp;#228...</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ccube constraint object-oriented database ...</td>\n",
       "      <td>alexander brodsky, victor e. segal, jia chen, ...</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>dual-buffering strategies in object bases</td>\n",
       "      <td>alfons kemper, donald kossmann</td>\n",
       "      <td>very large data bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>guest editorial</td>\n",
       "      <td>philip a. bernstein, yannis ioannidis, raghu r...</td>\n",
       "      <td>the vldb journal &amp;mdash; the international jou...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>graphdb: modeling and querying graphs in datab...</td>\n",
       "      <td>ralf hartmut g&amp;#252;ting</td>\n",
       "      <td>very large data bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>review of the data warehouse toolkit: the comp...</td>\n",
       "      <td>alexander a. anisimov</td>\n",
       "      <td>acm sigmod record</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>bulk loading into an oodb: a performance study</td>\n",
       "      <td>janet l. wiener, jeffrey f. naughton</td>\n",
       "      <td>very large data bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2294 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     the wasa2 object-oriented workflow management ...   \n",
       "1     a user-centered interface for querying distrib...   \n",
       "2     world wide database-integrating the web, corba...   \n",
       "3              xml-based information mediation with mix   \n",
       "4     the ccube constraint object-oriented database ...   \n",
       "...                                                 ...   \n",
       "2289          dual-buffering strategies in object bases   \n",
       "2290                                    guest editorial   \n",
       "2291  graphdb: modeling and querying graphs in datab...   \n",
       "2292  review of the data warehouse toolkit: the comp...   \n",
       "2293     bulk loading into an oodb: a performance study   \n",
       "\n",
       "                                                authors  \\\n",
       "0                       gottfried vossen, mathias weske   \n",
       "1                     isabel f. cruz, kimberly m. james   \n",
       "2     athman bouguettaya, boualem benatallah, lily h...   \n",
       "3     chaitan baru, amarnath gupta, bertram lud&#228...   \n",
       "4     alexander brodsky, victor e. segal, jia chen, ...   \n",
       "...                                                 ...   \n",
       "2289                     alfons kemper, donald kossmann   \n",
       "2290  philip a. bernstein, yannis ioannidis, raghu r...   \n",
       "2291                           ralf hartmut g&#252;ting   \n",
       "2292                              alexander a. anisimov   \n",
       "2293               janet l. wiener, jeffrey f. naughton   \n",
       "\n",
       "                                                  venue  year  \n",
       "0        international conference on management of data  1999  \n",
       "1        international conference on management of data  1999  \n",
       "2        international conference on management of data  1999  \n",
       "3        international conference on management of data  1999  \n",
       "4        international conference on management of data  1999  \n",
       "...                                                 ...   ...  \n",
       "2289                              very large data bases  1994  \n",
       "2290  the vldb journal &mdash; the international jou...  2003  \n",
       "2291                              very large data bases  1994  \n",
       "2292                                 acm sigmod record   2003  \n",
       "2293                              very large data bases  1994  \n",
       "\n",
       "[2294 rows x 4 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "573343df-2c41-49f2-8335-8f244f0d24d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic integration of environmental models f...</td>\n",
       "      <td>d. scott mackay</td>\n",
       "      <td>sigmod record</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estimation of query-result distribution and it...</td>\n",
       "      <td>viswanath poosala, yannis e. ioannidis</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incremental maintenance for non-distributive a...</td>\n",
       "      <td>themistoklis palpanas, richard sidle, hamid pi...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cost-based selection of path expression proces...</td>\n",
       "      <td>zhao-hui tang, georges gardarin, jean-robert g...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benchmarking spatial join operations with spat...</td>\n",
       "      <td>erik g. hoel, hanan samet</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>a simple algorithm for finding frequent elemen...</td>\n",
       "      <td>scott shenker, christos h. papadimitriou, rich...</td>\n",
       "      <td>acm trans. database syst.</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>sash: a self-adaptive histogram set for dynami...</td>\n",
       "      <td>lipyeow lim, min wang, jeffrey scott vitter</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>locally adaptive dimensionality reduction for ...</td>\n",
       "      <td>kaushik chakrabarti, eamonn j. keogh, michael ...</td>\n",
       "      <td>acm trans. database syst.</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>chair's message</td>\n",
       "      <td>richard t. snodgrass</td>\n",
       "      <td>sigmod record</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>indexing and querying xml data for regular pat...</td>\n",
       "      <td>bongki moon, quanzhong li</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2616 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     semantic integration of environmental models f...   \n",
       "1     estimation of query-result distribution and it...   \n",
       "2     incremental maintenance for non-distributive a...   \n",
       "3     cost-based selection of path expression proces...   \n",
       "4     benchmarking spatial join operations with spat...   \n",
       "...                                                 ...   \n",
       "2611  a simple algorithm for finding frequent elemen...   \n",
       "2612  sash: a self-adaptive histogram set for dynami...   \n",
       "2613  locally adaptive dimensionality reduction for ...   \n",
       "2614                                    chair's message   \n",
       "2615  indexing and querying xml data for regular pat...   \n",
       "\n",
       "                                                authors  \\\n",
       "0                                       d. scott mackay   \n",
       "1                viswanath poosala, yannis e. ioannidis   \n",
       "2     themistoklis palpanas, richard sidle, hamid pi...   \n",
       "3     zhao-hui tang, georges gardarin, jean-robert g...   \n",
       "4                             erik g. hoel, hanan samet   \n",
       "...                                                 ...   \n",
       "2611  scott shenker, christos h. papadimitriou, rich...   \n",
       "2612        lipyeow lim, min wang, jeffrey scott vitter   \n",
       "2613  kaushik chakrabarti, eamonn j. keogh, michael ...   \n",
       "2614                               richard t. snodgrass   \n",
       "2615                          bongki moon, quanzhong li   \n",
       "\n",
       "                          venue  year  \n",
       "0                 sigmod record  1999  \n",
       "1                          vldb  1996  \n",
       "2                          vldb  2002  \n",
       "3                          vldb  1996  \n",
       "4                          vldb  1995  \n",
       "...                         ...   ...  \n",
       "2611  acm trans. database syst.  2003  \n",
       "2612                       vldb  2003  \n",
       "2613  acm trans. database syst.  2002  \n",
       "2614              sigmod record  2001  \n",
       "2615                       vldb  2001  \n",
       "\n",
       "[2616 rows x 4 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dblp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b787fa0-9b6d-482c-9396-2148f2703841",
   "metadata": {},
   "source": [
    "### C. \n",
    "\n",
    "Convert multiple spaces to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cf5f35-56d4-492b-8704-21418973cd2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_acm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_acm\u001b[49m.columns:\n\u001b[32m      2\u001b[39m     df_acm[col].replace(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms \u001b[39m\u001b[33m{\u001b[39m\u001b[33m2,}\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m, regex=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m df_acm\n",
      "\u001b[31mNameError\u001b[39m: name 'df_acm' is not defined"
     ]
    }
   ],
   "source": [
    "for col in df_acm.columns:\n",
    "    df_acm[col].replace(r'\\s {2,}', ' ', regex=True)\n",
    "\n",
    "df_acm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8daacc69-d6f1-4a57-818b-8d744bfd1789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic integration of environmental models f...</td>\n",
       "      <td>d. scott mackay</td>\n",
       "      <td>sigmod record</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estimation of query-result distribution and it...</td>\n",
       "      <td>viswanath poosala, yannis e. ioannidis</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incremental maintenance for non-distributive a...</td>\n",
       "      <td>themistoklis palpanas, richard sidle, hamid pi...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cost-based selection of path expression proces...</td>\n",
       "      <td>zhao-hui tang, georges gardarin, jean-robert g...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benchmarking spatial join operations with spat...</td>\n",
       "      <td>erik g. hoel, hanan samet</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>a simple algorithm for finding frequent elemen...</td>\n",
       "      <td>scott shenker, christos h. papadimitriou, rich...</td>\n",
       "      <td>acm trans. database syst.</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>sash: a self-adaptive histogram set for dynami...</td>\n",
       "      <td>lipyeow lim, min wang, jeffrey scott vitter</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>locally adaptive dimensionality reduction for ...</td>\n",
       "      <td>kaushik chakrabarti, eamonn j. keogh, michael ...</td>\n",
       "      <td>acm trans. database syst.</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>chair's message</td>\n",
       "      <td>richard t. snodgrass</td>\n",
       "      <td>sigmod record</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>indexing and querying xml data for regular pat...</td>\n",
       "      <td>bongki moon, quanzhong li</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2616 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     semantic integration of environmental models f...   \n",
       "1     estimation of query-result distribution and it...   \n",
       "2     incremental maintenance for non-distributive a...   \n",
       "3     cost-based selection of path expression proces...   \n",
       "4     benchmarking spatial join operations with spat...   \n",
       "...                                                 ...   \n",
       "2611  a simple algorithm for finding frequent elemen...   \n",
       "2612  sash: a self-adaptive histogram set for dynami...   \n",
       "2613  locally adaptive dimensionality reduction for ...   \n",
       "2614                                    chair's message   \n",
       "2615  indexing and querying xml data for regular pat...   \n",
       "\n",
       "                                                authors  \\\n",
       "0                                       d. scott mackay   \n",
       "1                viswanath poosala, yannis e. ioannidis   \n",
       "2     themistoklis palpanas, richard sidle, hamid pi...   \n",
       "3     zhao-hui tang, georges gardarin, jean-robert g...   \n",
       "4                             erik g. hoel, hanan samet   \n",
       "...                                                 ...   \n",
       "2611  scott shenker, christos h. papadimitriou, rich...   \n",
       "2612        lipyeow lim, min wang, jeffrey scott vitter   \n",
       "2613  kaushik chakrabarti, eamonn j. keogh, michael ...   \n",
       "2614                               richard t. snodgrass   \n",
       "2615                          bongki moon, quanzhong li   \n",
       "\n",
       "                          venue  year  \n",
       "0                 sigmod record  1999  \n",
       "1                          vldb  1996  \n",
       "2                          vldb  2002  \n",
       "3                          vldb  1996  \n",
       "4                          vldb  1995  \n",
       "...                         ...   ...  \n",
       "2611  acm trans. database syst.  2003  \n",
       "2612                       vldb  2003  \n",
       "2613  acm trans. database syst.  2002  \n",
       "2614              sigmod record  2001  \n",
       "2615                       vldb  2001  \n",
       "\n",
       "[2616 rows x 4 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df_dblp2.columns:\n",
    "    df_dblp2[col].replace(r'\\s {2,}', ' ', regex=True)\n",
    "\n",
    "df_dblp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06fc4f-c4bb-48b7-9bb9-d6262a78eed0",
   "metadata": {},
   "source": [
    "### D.\n",
    "\n",
    "Use Levenshtein similarity $(L_{sim}(S_1, S_2) = 1 - \\frac{MED(S_1, S_2}{MAX(|S_1|, |S_2|})$\n",
    "for comparing the values in the **title** attribute and compute the score $(s_t)$. (MED refers to the minimum edit distance and $|S_i|$ is the number of characters in string $S_i$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcfcca-8e62-4418-9ea4-4dcf275212b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eafbbbd-7219-4a43-9306-89ab3d6637d4",
   "metadata": {},
   "source": [
    "### E. \n",
    "\n",
    "Use Jaro similarity to compare the values in the **authors** field and compute $(S_a)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15846622-b4ca-4112-b069-86f87ce4fcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d1d5145",
   "metadata": {},
   "source": [
    "### F.\n",
    "\n",
    "Use a modified version of the affine similarity that is scaled to the interval [0, 1] for the venue attribute $(S_c)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae173959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56547e65",
   "metadata": {},
   "source": [
    "### G.\n",
    "\n",
    "Use Match (1) / Mismatch (0) for the year $(S_y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebef187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b28dbe71",
   "metadata": {},
   "source": [
    "### H.\n",
    "\n",
    "Use the formula $\\text{rec\\_sim} = w_1 * s_1 + w_2 * s_2 + w_3 * s_3 + w_4 * s_4$ to combine the scores and compute the final score, where $\\sum^4_{i=1}w_i=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf308a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec8507ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfd1b170",
   "metadata": {},
   "source": [
    "### I.\n",
    "\n",
    "Report the records with rec_sim > 0.7 as duplicate records by storing the ids of both records in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ff59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc3795ea",
   "metadata": {},
   "source": [
    "### J.\n",
    "\n",
    "In the table `DBLP-ACM_perfectMapping.csv`, you can find the actual mappings (the ids of the correct duplicate records). Compute the precision of this method by counting the number of duplicate records that you discovered correctly. That is, among all the reported similar records by your method, how many pairs exist in the file `DBLP-ACM_perfectMapping.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92522b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b255e9",
   "metadata": {},
   "source": [
    "### K.\n",
    "\n",
    "Record the running time of the method. You can observe that the program takes a long time to get the results. What can you do to reduce the running time? (Just provide clear discussion – no need for implementing the ideas.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bf4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014262fc",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "### 1.\n",
    "\n",
    "Concatenate the values in each record into one single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47ec66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06d6fa1b",
   "metadata": {},
   "source": [
    "### 2.\n",
    "\n",
    "Change all alphabetical characters into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6453b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8837cd7c",
   "metadata": {},
   "source": [
    "### 3.\n",
    "\n",
    "Convert multiple spaces to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26370f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d36b4d",
   "metadata": {},
   "source": [
    "### 4.\n",
    "\n",
    "Combine the records from both tables into one big list as we did during the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca8f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79d6df97",
   "metadata": {},
   "source": [
    "### 5.\n",
    "\n",
    "Use the functions in the tutorials from lab 5 to compute the shingles, the minhash signature and the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff81975a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25552f2f",
   "metadata": {},
   "source": [
    "### 6.\n",
    "\n",
    "Extract the top 2224 candidates from the LSH algorithm, compare them to the actual mappings in the file `DBLP-ACM_perfectMapping.csv` and compute the precision of the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ec9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94f3390d",
   "metadata": {},
   "source": [
    "### 7.\n",
    "\n",
    "Record the running time of the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7448105f",
   "metadata": {},
   "source": [
    "### 8. \n",
    "\n",
    "Compare the precision and the running time in Parts 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519d398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5d8998d",
   "metadata": {},
   "source": [
    "## Task 3. Data preperation\n",
    "\n",
    "For this task, use the Pima Indians Diabetes Database.\n",
    "\n",
    "### 1. \n",
    "\n",
    "Compute the correlation between the different columns after removing the `outcome` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424ca98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a64c591",
   "metadata": {},
   "source": [
    "### 2.\n",
    "\n",
    "Remove the disguised values from the table. We need to remove the values that equal to `0` from columns `BloodPressure`, `SkinThickness` and `BMI` as these are missing values but they have been replaced by the value `0`. Remove the value but keep the record (i.e.) change the value to `null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75277d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afce5368",
   "metadata": {},
   "source": [
    "### 3.\n",
    "\n",
    "Fill the cells with `null` using the mean values of the records that have the same class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123ad09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59db4494",
   "metadata": {},
   "source": [
    "### 4.\n",
    "\n",
    "Compute the correlation between the different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dfb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34351176",
   "metadata": {},
   "source": [
    "### 5.\n",
    "\n",
    "Compare the values from this step with the values in the first step (just mention the most important changes (if any)) and comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fca39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
